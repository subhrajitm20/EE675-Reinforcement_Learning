{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbR5u3kZaL6c",
        "outputId": "83a4cd09-9192-439d-93ec-9268948da5e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEPRECATION: lightning-lite 1.8.0 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of lightning-lite or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
            "DEPRECATION: pytorch-lightning 1.8.0 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    if installed:\n",
        "        print('Installed')\n",
        "except:\n",
        "    !pip install -q gym[atari,accept-rom-license] ale-py\n",
        "    installed = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t2EBzuBAaRbJ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import copy\n",
        "import random\n",
        "import gc\n",
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import ipywidgets as widgets\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from gym import spaces\n",
        "from tqdm import tqdm\n",
        "from collections import deque\n",
        "from IPython import display\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import animation\n",
        "\n",
        "cv2.ocl.setUseOpenCL(False)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aiHjxDJMpKyw"
      },
      "outputs": [],
      "source": [
        "class Replay_Buffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def store(self, state, action, new_state, reward, done):\n",
        "        state = np.expand_dims(state, 0)\n",
        "        new_state = np.expand_dims(new_state, 0)\n",
        "\n",
        "        self.buffer.append([state, action, new_state, reward, done])\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        state, action, new_state, reward, done = zip(\n",
        "            *random.sample(self.buffer, batch_size)\n",
        "        )\n",
        "\n",
        "        return np.concatenate(state), action, np.concatenate(new_state), reward, done\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "eCMFUsVJpNb4",
        "outputId": "d131af15-68f9-4885-f64a-7c389ec17460"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGvCAYAAACJsNWPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAumklEQVR4nO3de3RU9b338c9cMpN7gAAhQAgBRaMoaihIkKNYjQUfejzLVs6yFaTQxyxtESj2SOnS4vI0yyosqhW0BeRxFZF6wWPPSZX0tHK1WmJQK6koIOGSEBMgFwK5zOznj2QGQkKYmczsnUner7X2ItnZe+abn+h8/N22zTAMQwAAABaxW10AAADo2wgjAADAUoQRAABgKcIIAACwFGEEAABYijACAAAsRRgBAACWIowAAABLOa0uIBBer1fHjh1TUlKSbDab1eUAAIAAGIahuro6DR06VHb7xfs/oiKMHDt2TBkZGVaXAQAAQnD48GENHz78oj+PijCSlJQkqfWXSU5OtrgaAAAQiNraWmVkZPg/xy8mKsKIb2gmOTmZMAIAQJS51BQLJrACAABLEUYAAIClCCMAAMBShBEAAGApwggAALAUYQQAAFiKMAIAACxFGAEAAJYijAAAAEsFHUa2bdumGTNmaOjQobLZbHrrrbcuec/WrVuVk5Oj2NhYjRo1Si+88EIotQIAgF4o6DBy+vRpjRs3Tr/5zW8Cuv7gwYOaPn26pkyZopKSEv3sZz/T/Pnz9cYbbwRdLAAA6H2CfjbNtGnTNG3atICvf+GFFzRixAitXLlSkpSdna3du3frmWee0d133x3s2wMAgF4m4nNG3n//feXl5bU7d8cdd2j37t1qbm7u9J7GxkbV1ta2OyLh+b9+qXt/9ze9+1lFRF4fAABcWsTDSEVFhdLS0tqdS0tLU0tLi6qqqjq9p6CgQCkpKf4jIyMjIrXtO16nXfurdfhEQ0ReHwAAXJopq2kufHSwYRidnvdZsmSJampq/Mfhw4cjUle8yyFJamjyROT1AQDApQU9ZyRYQ4YMUUVF+2GQyspKOZ1OpaamdnqP2+2W2+2OdGmKi2n99QkjAABYJ+I9I5MmTVJRUVG7c1u2bNH48eMVExMT6bfvkq9n5ExTi6V1AADQlwUdRurr67Vnzx7t2bNHUuvS3T179qisrExS6xDLrFmz/Nfn5+fr0KFDWrRokUpLS7Vu3TqtXbtWixcvDs9v0A1xDNMAAGC5oIdpdu/eralTp/q/X7RokSRp9uzZWr9+vcrLy/3BRJKysrJUWFiohQsX6vnnn9fQoUP17LPP9ohlvf45I82EEQAArBJ0GLnlllv8E1A7s379+g7nbr75Zn300UfBvlXEnRumIYwAAGCVPv1smjiXbwIrc0YAALBKnw4j8TH0jAAAYLW+HUaYwAoAgOX6dBhhNQ0AANbr02Ekvm3OyBlW0wAAYJk+HkZ8PSNMYAUAwCp9Ooz4hmnONnvl9V58uTIAAIicPh1GfD0jEkM1AABYpU+HkVjnuTDCJFYAAKzRp8OI3W5THHuNAABgqT4dRqTzn0/DJFYAAKzQ58MIe40AAGCtPh9GeFgeAADW6vNh5NzD8ggjAABYoc+HEd/D8tj4DAAAaxBGGKYBAMBSfT6MMIEVAABr9fkw4u8ZYQdWAAAsQRjxT2BlzggAAFbo82GEYRoAAKzV58NIPNvBAwBgqT4fRugZAQDAWn0+jMSz6RkAAJYijPhX0zCBFQAAK/T5MMIwDQAA1urzYYQdWAEAsBZhhJ4RAAAs1efDSFwME1gBALBSnw8j54ZpmMAKAIAVCCO+YZpmjwzDsLgaAAD6nj4fRnyraQxDamzxWlwNAAB9T58PI75NzyTmjQAAYIU+H0YcdptcztZm4Mm9AACYr8+HEYm9RgAAsBJhROee3MswDQAA5iOMSIp3t84bOc0wDQAApiOMSEpoCyMNjfSMAABgNsKIpIS2OSP0jAAAYD7CiM71jJymZwQAANMRRnRez0gjPSMAAJiNMKJzPSP1hBEAAExHGNF5E1iZMwIAgOkII5ISXL6eEeaMAABgNsKIpAS3b9MzekYAADAbYUTnr6YhjAAAYDbCiFjaCwCAlQgjYtMzAACsRBgRwzQAAFiJMKJzq2kYpgEAwHyEEZ1bTcMwDQAA5iOMqP0wjWEYFlcDAEDfQhjRuTDiNaTGFq/F1QAA0LcQRiTFxzj8X/N8GgAAzEUYkWS32xTftry3gUmsAACYijDSJt7Fk3sBALACYaRNIs+nAQDAEoSRNr5JrPSMAABgrpDCyKpVq5SVlaXY2Fjl5ORo+/btXV6/YcMGjRs3TvHx8UpPT9ecOXNUXV0dUsGR4tv4rKGJOSMAAJgp6DCyadMmLViwQEuXLlVJSYmmTJmiadOmqaysrNPrd+zYoVmzZmnu3Ln67LPP9Nprr+nvf/+75s2b1+3iw8m38Rk9IwAAmCvoMLJixQrNnTtX8+bNU3Z2tlauXKmMjAytXr260+v/9re/aeTIkZo/f76ysrJ000036YEHHtDu3bu7XXw4xbcN0zQQRgAAMFVQYaSpqUnFxcXKy8trdz4vL0+7du3q9J7c3FwdOXJEhYWFMgxDx48f1+uvv64777zzou/T2Nio2tradkekJfqeT8MwDQAApgoqjFRVVcnj8SgtLa3d+bS0NFVUVHR6T25urjZs2KCZM2fK5XJpyJAh6tevn5577rmLvk9BQYFSUlL8R0ZGRjBlhiTe93waekYAADBVSBNYbTZbu+8Nw+hwzmfv3r2aP3++HnvsMRUXF+udd97RwYMHlZ+ff9HXX7JkiWpqavzH4cOHQykzKInnPZ8GAACYxxnMxQMHDpTD4ejQC1JZWdmht8SnoKBAkydP1iOPPCJJuvbaa5WQkKApU6boySefVHp6eod73G633G53MKV1WzzDNAAAWCKonhGXy6WcnBwVFRW1O19UVKTc3NxO72loaJDd3v5tHI7WIZGe9ITcRIZpAACwRNDDNIsWLdKaNWu0bt06lZaWauHChSorK/MPuyxZskSzZs3yXz9jxgy9+eabWr16tQ4cOKCdO3dq/vz5mjBhgoYOHRq+36Sb6BkBAMAaQQ3TSNLMmTNVXV2tJ554QuXl5Ro7dqwKCwuVmZkpSSovL2+358j999+vuro6/eY3v9FPfvIT9evXT7feequeeuqp8P0WYZDAnBEAACxhM3rSWMlF1NbWKiUlRTU1NUpOTo7Ie2z/4mvdt/ZDXTkkSe8s+JeIvAcAAH1JoJ/fPJumjb9nhAflAQBgKsJIm3NLe5kzAgCAmQgjbeJdPJsGAAArEEbaJLljJElNLV41tXgtrgYAgL6DMNLG99ReiRU1AACYiTDSxumwM1QDAIAFCCPn8U1irT3bbHElAAD0HYSR8yTGtoaR+rP0jAAAYBbCyHmS2npGGKYBAMA8hJHzJMW2rqipo2cEAADTEEbO45szUkfPCAAApiGMnIc5IwAAmI8wcp6ktjBSx2oaAABMQxg5DxNYAQAwH2HkPAzTAABgPsLIeRLbnk/DBFYAAMxDGDkPc0YAADAfYeQ8/mEaekYAADANYeQ8/gmszBkBAMA0hJHzsAMrAADmI4ycxzdMwwRWAADMQxg5j287+KYWrxpbPBZXAwBA30AYOY8vjEjMGwEAwCyEkfM47DYluBySWFEDAIBZCCMX8M8boWcEAABTEEYukMjzaQAAMBVh5AIs7wUAwFyEkQsk+XdhZUt4AADMQBi5QCK7sAIAYCrCyAV8PSO1hBEAAExBGLlAort1zggTWAEAMAdh5AL+J/fSMwIAgCkIIxdIYmkvAACmIoxcIMm/6RmraQAAMANh5AKJTGAFAMBUhJELJLPpGQAApiKMXCA5rjWM1J5hmAYAADMQRi6QQhgBAMBUhJELJPsmsDa2yOM1LK4GAIDejzByAd8wjcSKGgAAzEAYuUCMw654l0OSVHuGSawAAEQaYaQTvhU1tfSMAAAQcYSRTiTHtc4bqWESKwAAEUcY6YS/Z4QwAgBAxBFGOuFf3sswDQAAEUcY6cS5jc+YwAoAQKQRRjrh22uEOSMAAEQeYaQTDNMAAGAewkgneD4NAADmIYx0wreahmEaAAAijzDSCd8+I7VnmcAKAECkEUY6wTANAADmIYx0gmEaAADMQxjpBKtpAAAwD2GkE75hmrPNXjW2eCyuBgCA3o0w0okkt1M2W+vXdUxiBQAgoggjnbDbbUp0swsrAABmCCmMrFq1SllZWYqNjVVOTo62b9/e5fWNjY1aunSpMjMz5Xa7NXr0aK1bty6kgs3Ck3sBADCHM9gbNm3apAULFmjVqlWaPHmyXnzxRU2bNk179+7ViBEjOr3nnnvu0fHjx7V27VpddtllqqysVEtLzx7+SImL0dFTZ9hrBACACAs6jKxYsUJz587VvHnzJEkrV67Uu+++q9WrV6ugoKDD9e+88462bt2qAwcOaMCAAZKkkSNHdq9qE/g2PmOYBgCAyApqmKapqUnFxcXKy8trdz4vL0+7du3q9J63335b48eP169+9SsNGzZMY8aM0eLFi3XmzJmLvk9jY6Nqa2vbHWZjmAYAAHME1TNSVVUlj8ejtLS0dufT0tJUUVHR6T0HDhzQjh07FBsbq82bN6uqqkoPPvigTpw4cdF5IwUFBVq2bFkwpYUde40AAGCOkCaw2nzrXtsYhtHhnI/X65XNZtOGDRs0YcIETZ8+XStWrND69esv2juyZMkS1dTU+I/Dhw+HUma3+PYaqWkgjAAAEElB9YwMHDhQDoejQy9IZWVlh94Sn/T0dA0bNkwpKSn+c9nZ2TIMQ0eOHNHll1/e4R632y232x1MaWHXry2MnCKMAAAQUUH1jLhcLuXk5KioqKjd+aKiIuXm5nZ6z+TJk3Xs2DHV19f7z+3bt092u13Dhw8PoWRz9EtwSZJOnWmyuBIAAHq3oIdpFi1apDVr1mjdunUqLS3VwoULVVZWpvz8fEmtQyyzZs3yX3/vvfcqNTVVc+bM0d69e7Vt2zY98sgj+sEPfqC4uLjw/SZh5usZOUnPCAAAERX00t6ZM2equrpaTzzxhMrLyzV27FgVFhYqMzNTklReXq6ysjL/9YmJiSoqKtKPf/xjjR8/Xqmpqbrnnnv05JNPhu+3iID+8a09I8wZAQAgsmyGYRhWF3EptbW1SklJUU1NjZKTk015z38crdH/eW6HBie59eHS20x5TwAAepNAP795Ns1F9Is/N4E1CvIaAABRizByEb5hmiaPV2eaPRZXAwBA70UYuYh4l0Mxjta9U5jECgBA5BBGLsJms6lfW+/IqQaW9wIAECmEkS6w8RkAAJFHGOlCf3/PCGEEAIBIIYx0wbei5iTDNAAARAxhpAvnlvcSRgAAiBTCSBcYpgEAIPIII11Iief5NAAARBphpAv+59Pw5F4AACKGMNIFntwLAEDkEUa6wKZnAABEHmGkC/0T2PQMAIBII4x0oV9cW8/IGZ7cCwBApBBGuuDbZ8TjNVTX2GJxNQAA9E6EkS7ExjgUG9PaRKdOM1QDAEAkEEYuwb/xGct7AQCICMLIJaSwvBcAgIgijFzCgITWnpETpxstrgQAgN6JMHIJqYluSVJ1PcM0AABEAmHkElL9PSOEEQAAIoEwcgkDCCMAAEQUYeQSfGGkmjACAEBEEEYugWEaAAAiizByCecmsLKaBgCASCCMXALDNAAARBZh5BJ8wzR1Z1vU1OK1uBoAAHofwsglpMTFyGG3SZJONtA7AgBAuBFGLsFut6l/29N72fgMAIDwI4wEIDWhbRIrW8IDABB2hJEAsPEZAACRQxgJwIDEthU1DNMAABB2hJEAsPEZAACRQxgJAHuNAAAQOYSRAPh2YT3BBFYAAMKOMBIA3zANc0YAAAg/wkgAWE0DAEDkEEYCkMqcEQAAIoYwEgBfz0jNmWY1e3g+DQAA4UQYCUC/eJfaHk/DUA0AAGFGGAmAw27zr6j5uo4VNQAAhBNhJECDfGGknjACAEA4EUYCNDiZnhEAACKBMBKgQQzTAAAQEYSRAA1KIowAABAJhJEAEUYAAIgMwkiACCMAAEQGYSRArKYBACAyCCMBomcEAIDIIIwEyBdG6htb1NDUYnE1AAD0HoSRACW6nYqNaW2uqjq2hAcAIFwIIwGy2WwanBQrSaqsO2txNQAA9B6EkSAwbwQAgPAjjASBFTUAAIQfYSQI9IwAABB+hJEgEEYAAAi/kMLIqlWrlJWVpdjYWOXk5Gj79u0B3bdz5045nU5dd911obyt5QgjAACEX9BhZNOmTVqwYIGWLl2qkpISTZkyRdOmTVNZWVmX99XU1GjWrFn65je/GXKxVmPOCAAA4Rd0GFmxYoXmzp2refPmKTs7WytXrlRGRoZWr17d5X0PPPCA7r33Xk2aNCnkYq02OLk1jFTUsLQXAIBwCSqMNDU1qbi4WHl5ee3O5+XladeuXRe976WXXtL+/fv1+OOPB/Q+jY2Nqq2tbXf0BENSWvcZqapvVIvHa3E1AAD0DkGFkaqqKnk8HqWlpbU7n5aWpoqKik7v+eKLL/Too49qw4YNcjqdAb1PQUGBUlJS/EdGRkYwZUbMwAS3nHabvAZDNQAAhEtIE1htNlu77w3D6HBOkjwej+69914tW7ZMY8aMCfj1lyxZopqaGv9x+PDhUMoMO7vdprTk1t6RcoZqAAAIi8C6KtoMHDhQDoejQy9IZWVlh94SSaqrq9Pu3btVUlKiH/3oR5Ikr9crwzDkdDq1ZcsW3XrrrR3uc7vdcrvdwZRmmiEpsTp66oyOE0YAAAiLoHpGXC6XcnJyVFRU1O58UVGRcnNzO1yfnJysTz/9VHv27PEf+fn5uuKKK7Rnzx5NnDixe9VbYAg9IwAAhFVQPSOStGjRIt13330aP368Jk2apN/+9rcqKytTfn6+pNYhlqNHj+rll1+W3W7X2LFj290/ePBgxcbGdjgfLXyTWI/XEkYAAAiHoMPIzJkzVV1drSeeeELl5eUaO3asCgsLlZmZKUkqLy+/5J4j0YyeEQAAwstmGIZhdRGXUltbq5SUFNXU1Cg5OdnSWv748TH9eGOJJowcoD/kR++eKQAARFqgn988myZIvmGaCoZpAAAIC8JIkHzDNBW1ZxUFnUoAAPR4hJEg+fYZaWrx6mRDs8XVAAAQ/QgjQXI57RqY6JIkldecsbgaAACiH2EkBCzvBQAgfAgjIWB5LwAA4UMYCYG/Z4QwAgBAtxFGQpCeEidJOkYYAQCg2wgjIRjar7Vn5NgpJrACANBdhJEQDOsXL0k6cpIwAgBAdxFGQjC8f+swTXnNGXm9bHwGAEB3EEZCkJYcK6fdpmaPocq6RqvLAQAgqhFGQuCw2/wrao6cbLC4GgAAohthJES+oZqjTGIFAKBbCCMhYhIrAADhQRgJ0bC2nhHCCAAA3UMYCdFwfxhhzggAAN1BGAnR8H7MGQEAIBwIIyEa3r91zsjRk2dkGOw1AgBAqAgjIRqSEiubTWps8aqqvsnqcgAAiFqEkRC5nHalJbXuNcJQDQAAoSOMdAOTWAEA6D7CSDf4wsjhE/SMAAAQKsJIN2SmJkiSDlWftrgSAACiF2GkG0YObF1R8xVhBACAkBFGuuFczwhzRgAACBVhpBtGtoWR8pqzOtvssbgaAACiE2GkG/rHxyjJ7ZQkHT5B7wgAAKEgjHSDzWZTpn/eCGEEAIBQEEa6iRU1AAB0D2Gkm0amsqIGAIDuIIx0EytqAADoHsJIN2UOoGcEAIDuIIx008iBrT0jR0+eUVOL1+JqAACIPoSRbhqc5FZcjENegwfmAQAQCsJIN9lsNn/vyIGvGaoBACBYhJEwuGxwoiTpy6/rLa4EAIDoQxgJg8sGtYWRSsIIAADBIoyEgb9nhDACAEDQCCNhMHpw65yR/ZX1MgzD4moAAIguhJEwyBqYILtNqmtsUWVdo9XlAAAQVQgjYeB2OjSibfOz/QzVAAAQFMJImLCiBgCA0BBGwmQ0k1gBAAgJYSRMWN4LAEBoCCNhwvJeAABCQxgJE18Yqaxr1MnTTRZXAwBA9CCMhElSbIwyBsRJkkorai2uBgCA6EEYCaPsIcmSpNLyOosrAQAgehBGwujK9NYw8s9yekYAAAgUYSSMrkpPksQwDQAAwSCMhNGVbcM0+47Xq8XjtbgaAACiA2EkjEYMiFeCy6GmFq8OVp22uhwAAKICYSSM7HabrhjSOlSzl3kjAAAEhDASZv5JrBWsqAEAIBCEkTDLbgsje4/RMwIAQCAII2E2dmhrGPn0aI0Mw7C4GgAAer6QwsiqVauUlZWl2NhY5eTkaPv27Re99s0339Ttt9+uQYMGKTk5WZMmTdK7774bcsE9XXZ6spx2m06cbtKRk2esLgcAgB4v6DCyadMmLViwQEuXLlVJSYmmTJmiadOmqaysrNPrt23bpttvv12FhYUqLi7W1KlTNWPGDJWUlHS7+J4oNsahK9v2G/nkSI3F1QAA0PPZjCDHEiZOnKgbbrhBq1ev9p/Lzs7WXXfdpYKCgoBe4+qrr9bMmTP12GOPBXR9bW2tUlJSVFNTo+Tk5GDKtcTSzZ9qwwdleuBfRmnJ9GyrywEAwBKBfn4H1TPS1NSk4uJi5eXltTufl5enXbt2BfQaXq9XdXV1GjBgwEWvaWxsVG1tbbsjmowb3k+S9PGRU5bWAQBANAgqjFRVVcnj8SgtLa3d+bS0NFVUVAT0GsuXL9fp06d1zz33XPSagoICpaSk+I+MjIxgyrTctRkpkqR/HK2V18skVgAAuhLSBFabzdbue8MwOpzrzMaNG/WLX/xCmzZt0uDBgy963ZIlS1RTU+M/Dh8+HEqZlrlsUKLiYhyqb2zRgap6q8sBAKBHCyqMDBw4UA6Ho0MvSGVlZYfekgtt2rRJc+fO1R/+8AfddtttXV7rdruVnJzc7ogmTodd1wxr7R3Zc5hJrAAAdCWoMOJyuZSTk6OioqJ254uKipSbm3vR+zZu3Kj7779fr7zyiu68887QKo0y49qGakrKTlpcCQAAPVvQwzSLFi3SmjVrtG7dOpWWlmrhwoUqKytTfn6+pNYhllmzZvmv37hxo2bNmqXly5frxhtvVEVFhSoqKlRT07t7DHIyWyfo7v6KMAIAQFecwd4wc+ZMVVdX64knnlB5ebnGjh2rwsJCZWZmSpLKy8vb7Tny4osvqqWlRQ899JAeeugh//nZs2dr/fr13f8NeqjxI/tLkj4/XqdTDU3qF++yuCIAAHqmoPcZsUK07TPic+vy93Tg69NaO3u8vpnd9ZwaAAB6m4jsM4LgTBjZOlTz4VcnLK4EAICeizASQePbwsjfDxJGAAC4GMJIBPl6Rj49WqOzzR6LqwEAoGcijERQxoA4pSW71ewxVFJ2yupyAADokQgjEWSz2TQxK1WStGt/lcXVAADQMxFGIuymywdKkrZ/QRgBAKAzhJEIm9IWRj45cko1Dc0WVwMAQM9DGImw9JQ4XTY4UV6DoRoAADpDGDHBTZe1DdV8SRgBAOBChBET+IZqdjBvBACADggjJrhxVKpiHDaVnWjQga/rrS4HAIAehTBiggS307/E98+lxy2uBgCAnoUwYpLbr2p9UF7RXsIIAADnI4yY5La2MFJ86KSq6xstrgYAgJ6DMGKSYf3iNHZYsryG9L//rLS6HAAAegzCiIluzx4iSdryGUM1AAD4EEZMlHd161DN9i++Vt1ZdmMFAEAijJjqyiFJGj0oQY0tXr1L7wgAAJIII6ay2Wz61+uGSZL+a89Ri6sBAKBnIIyY7F+vGypJ2vlllSrrzlpcDQAA1iOMmCwzNUHXZfST15D+55Nyq8sBAMByhBEL+HpH3vjoiMWVAABgPcKIBf71umFyOez6x9FafXLklNXlAABgKcKIBQYkuDT9mtY9Rzb8rcziagAAsBZhxCL3TsyUJL398THVsucIAKAPI4xY5Bsj++vywYk60+zR5o9Y5gsA6LsIIxax2Wz6/o2tvSPrdh6Ux2tYXBEAANYgjFjou+OHq398jA5VN+hP/2CZLwCgbyKMWCje5dSsSSMlSS9s3S/DoHcEAND3EEYsNjt3pGJjWpf57viyyupyAAAwHWHEYgMSXPr3b4yQJD2zZR+9IwCAPocw0gM8NPUyxbsc+vjwKZ7mCwDocwgjPcCgJLfm3pQlSXr63X+qxeO1uCIAAMxDGOkhfvgvo9Q/Pkb7vz6tjR+yKysAoO8gjPQQybExWnj7GEnSr979XJV1Zy2uCAAAcxBGepDvTczUNcNSVHe2Rb/8n1KrywEAwBSEkR7EYbfpP/9trGw26a09x/TXf1ZaXRIAABFHGOlhrh3eT3NyWyezPvL6J6qqb7S4IgAAIosw0gP99FtXaExaoqrqG/XoG5+w9wgAoFcjjPRAsTEO/frfr5fLYdefSyu16r39VpcEAEDEEEZ6qOz0ZD3+7askSc9s+Vz/W8pmaACA3okw0oN9b2Kmvn/jCBmG9PCre/TpkRqrSwIAIOwIIz3c4zOu1qRRqapvbNGsdR9o3/E6q0sCACCsCCM9XIzDrt/OytG44Sk62dCs7635QJ9XEEgAAL0HYSQKJMXG6P/9YIKuHJKkr+sa9d0XdunvX52wuiwAAMKCMBIl+sW79Or/vVE5mf1Ve7ZF31/zgd4oPmJ1WQAAdBthJIr0i3fp93Mn6rbsNDW2ePWT1z7Wkjc/1dlmj9WlAQAQMsJIlIlzOfTifTlacNvlstmkjR+Wafqz27WbYRsAQJQijEQhh92mBbeN0fo5EzQoya0DX5/Wd198Xz/b/Km+rmP7eABAdCGMRLGbxwzSnxferO/mDJdhSK98UKZbnv6rVv55n2oamq0uDwCAgNiMKHjwSW1trVJSUlRTU6Pk5GSry+mR/nagWgWFpfq4bWO0eJdD94zP0JzJI5WZmmBxdQCAvijQz2/CSC9iGIYKP63Qc3/5Qv88by+SCSMH6N9uGKbpY9OVEh9jYYUAgL6EMNKHGYahHV9Wac32g9r2xdfy/RN22G3KyeyvqVcM1i1XDNIVaUmy223WFgsA6LUII5Akldec0X/tOaa3So626y2RpCS3U9eN6KeczP66ZliKxqQlaVi/OAIKACAsCCPo4PCJBv3180r95Z+V+vDgCTU0ddyfJN7l0OWDEzVqUKKG9YvTsP5x/j/TkmOV4HLIZiOsAAAujTCCLrV4vPr8eJ0+OnRSH5WdUml5rQ58fVpNHm+X97mcdqUmuDSg7UhNcCkpNkYJbqcS3Q4luJ1tX7f+GRfjkMtpl8thl8tpl9vZ+mdM2/cuh10xDhsBBwB6IcIIgtbi8eqr6gbtO16nQ9UNOnqqQUdPntHRU2d09OQZne6kJyVcYhw22W02Oew2OWw22Wytc1wc9nPn7Tab7HbJYbPJ3nadve1rX5Sx2VoPSfKdPff9uW/Ov973va2Tn/lfuf0f7X5GjuqZ+OfSc537NxY9yYNTRyt39MCwvmagn9/OUF581apVevrpp1VeXq6rr75aK1eu1JQpUy56/datW7Vo0SJ99tlnGjp0qH76058qPz8/lLdGBDkddl02OFGXDU7s9OcNTS2qrm/SidOtR/XpJp043aj6sy2qb/TodGOL6ptadLqx9ahv9Ohss0dNLV41tnjV1OJRs8dQk8crj7d9Bm72GJJ6fC4GgF7rnm9kWPbeQYeRTZs2acGCBVq1apUmT56sF198UdOmTdPevXs1YsSIDtcfPHhQ06dP1w9/+EP9/ve/186dO/Xggw9q0KBBuvvuu8PyS8Ac8S6n4gc4lTEgvtuv5fEaamrxtgYVj0ctHkMeryHDkDxG69deo/XweA15va3nvYYhr7f1nMdou74t2BhqXUnk+/r8LwwZ/lVF/j99lxjGeV+fu7HjdZ28VrdbApEQBR2+QI9zw4h+lr130MM0EydO1A033KDVq1f7z2VnZ+uuu+5SQUFBh+v/4z/+Q2+//bZKS0v95/Lz8/Xxxx/r/fffD+g9GaYBACD6BPr5HdR28E1NTSouLlZeXl6783l5edq1a1en97z//vsdrr/jjju0e/duNTd3vmV5Y2Ojamtr2x0AAKB3CiqMVFVVyePxKC0trd35tLQ0VVRUdHpPRUVFp9e3tLSoqqqq03sKCgqUkpLiPzIyrBvHAgAAkRXSg/IuXIZpGEaXSzM7u76z8z5LlixRTU2N/zh8+HAoZQIAgCgQ1ATWgQMHyuFwdOgFqays7ND74TNkyJBOr3c6nUpNTe30HrfbLbfbHUxpAAAgSgXVM+JyuZSTk6OioqJ254uKipSbm9vpPZMmTepw/ZYtWzR+/HjFxPDQNgAA+rqgh2kWLVqkNWvWaN26dSotLdXChQtVVlbm3zdkyZIlmjVrlv/6/Px8HTp0SIsWLVJpaanWrVuntWvXavHixeH7LQAAQNQKep+RmTNnqrq6Wk888YTKy8s1duxYFRYWKjMzU5JUXl6usrIy//VZWVkqLCzUwoUL9fzzz2vo0KF69tln2WMEAABIYjt4AAAQIRHZZwQAACDcCCMAAMBShBEAAGApwggAALAUYQQAAFgq6KW9VvAt+OGBeQAARA/f5/alFu5GRRipq6uTJB6YBwBAFKqrq1NKSspFfx4V+4x4vV4dO3ZMSUlJXT6QL1i1tbXKyMjQ4cOH2b8kwmhrc9DO5qCdzUE7myOS7WwYhurq6jR06FDZ7RefGRIVPSN2u13Dhw+P2OsnJyfzF90ktLU5aGdz0M7moJ3NEal27qpHxIcJrAAAwFKEEQAAYKk+HUbcbrcef/xxud1uq0vp9Whrc9DO5qCdzUE7m6MntHNUTGAFAAC9V5/uGQEAANYjjAAAAEsRRgAAgKUIIwAAwFK9PoysWrVKWVlZio2NVU5OjrZv397l9Vu3blVOTo5iY2M1atQovfDCCyZVGt2Caec333xTt99+uwYNGqTk5GRNmjRJ7777ronVRrdg/0777Ny5U06nU9ddd11kC+wlgm3nxsZGLV26VJmZmXK73Ro9erTWrVtnUrXRK9h23rBhg8aNG6f4+Hilp6drzpw5qq6uNqna6LRt2zbNmDFDQ4cOlc1m01tvvXXJe0z/LDR6sVdffdWIiYkxfve73xl79+41Hn74YSMhIcE4dOhQp9cfOHDAiI+PNx5++GFj7969xu9+9zsjJibGeP31102uPLoE284PP/yw8dRTTxkffvihsW/fPmPJkiVGTEyM8dFHH5lcefQJtq19Tp06ZYwaNcrIy8szxo0bZ06xUSyUdv72t79tTJw40SgqKjIOHjxofPDBB8bOnTtNrDr6BNvO27dvN+x2u/HrX//aOHDggLF9+3bj6quvNu666y6TK48uhYWFxtKlS4033njDkGRs3ry5y+ut+Czs1WFkwoQJRn5+frtzV155pfHoo492ev1Pf/pT48orr2x37oEHHjBuvPHGiNXYGwTbzp256qqrjGXLloW7tF4n1LaeOXOm8fOf/9x4/PHHCSMBCLad//SnPxkpKSlGdXW1GeX1GsG289NPP22MGjWq3blnn33WGD58eMRq7G0CCSNWfBb22mGapqYmFRcXKy8vr935vLw87dq1q9N73n///Q7X33HHHdq9e7eam5sjVms0C6WdL+T1elVXV6cBAwZEosReI9S2fumll7R//349/vjjkS6xVwilnd9++22NHz9ev/rVrzRs2DCNGTNGixcv1pkzZ8woOSqF0s65ubk6cuSICgsLZRiGjh8/rtdff1133nmnGSX3GVZ8FkbFg/JCUVVVJY/Ho7S0tHbn09LSVFFR0ek9FRUVnV7f0tKiqqoqpaenR6zeaBVKO19o+fLlOn36tO65555IlNhrhNLWX3zxhR599FFt375dTmev/dc9rEJp5wMHDmjHjh2KjY3V5s2bVVVVpQcffFAnTpxg3shFhNLOubm52rBhg2bOnKmzZ8+qpaVF3/72t/Xcc8+ZUXKfYcVnYa/tGfGx2WztvjcMo8O5S13f2Xm0F2w7+2zcuFG/+MUvtGnTJg0ePDhS5fUqgba1x+PRvffeq2XLlmnMmDFmlddrBPN32uv1ymazacOGDZowYYKmT5+uFStWaP369fSOXEIw7bx3717Nnz9fjz32mIqLi/XOO+/o4MGDys/PN6PUPsXsz8Je+79KAwcOlMPh6JCwKysrOyQ+nyFDhnR6vdPpVGpqasRqjWahtLPPpk2bNHfuXL322mu67bbbIllmrxBsW9fV1Wn37t0qKSnRj370I0mtH5qGYcjpdGrLli269dZbTak9moTydzo9PV3Dhg1r96j07OxsGYahI0eO6PLLL49ozdEolHYuKCjQ5MmT9cgjj0iSrr32WiUkJGjKlCl68skn6b0OEys+C3ttz4jL5VJOTo6KioranS8qKlJubm6n90yaNKnD9Vu2bNH48eMVExMTsVqjWSjtLLX2iNx///165ZVXGO8NULBtnZycrE8//VR79uzxH/n5+briiiu0Z88eTZw40azSo0oof6cnT56sY8eOqb6+3n9u3759stvtGj58eETrjVahtHNDQ4Ps9vYfWw6HQ9K5/3NH91nyWRixqbE9gG/Z2Nq1a429e/caCxYsMBISEoyvvvrKMAzDePTRR4377rvPf71vOdPChQuNvXv3GmvXrmVpbwCCbedXXnnFcDqdxvPPP2+Ul5f7j1OnTln1K0SNYNv6QqymCUyw7VxXV2cMHz7c+M53vmN89tlnxtatW43LL7/cmDdvnlW/QlQItp1feuklw+l0GqtWrTL2799v7Nixwxg/frwxYcIEq36FqFBXV2eUlJQYJSUlhiRjxYoVRklJiX8JdU/4LOzVYcQwDOP55583MjMzDZfLZdxwww3G1q1b/T+bPXu2cfPNN7e7/r333jOuv/56w+VyGSNHjjRWr15tcsXRKZh2vvnmmw1JHY7Zs2ebX3gUCvbv9PkII4ELtp1LS0uN2267zYiLizOGDx9uLFq0yGhoaDC56ugTbDs/++yzxlVXXWXExcUZ6enpxve+9z3jyJEjJlcdXf761792+d/cnvBZaDMM+rYAAIB1eu2cEQAAEB0IIwAAwFKEEQAAYCnCCAAAsBRhBAAAWIowAgAALEUYAQAAliKMAADQR23btk0zZszQ0KFDZbPZ9NZbbwX9GoZh6JlnntGYMWPkdruVkZGhX/7yl0G9Rq99UB4AAOja6dOnNW7cOM2ZM0d33313SK/x8MMPa8uWLXrmmWd0zTXXqKamRlVVVUG9BjuwAgAA2Ww2bd68WXfddZf/XFNTk37+859rw4YNOnXqlMaOHaunnnpKt9xyiySptLRU1157rf7xj3/oiiuuCPm9GaYBAACdmjNnjnbu3KlXX31Vn3zyib773e/qW9/6lr744gtJ0h//+EeNGjVK//3f/62srCyNHDlS8+bN04kTJ4J6H8IIAADoYP/+/dq4caNee+01TZkyRaNHj9bixYt100036aWXXpIkHThwQIcOHdJrr72ml19+WevXr1dxcbG+853vBPVezBkBAAAdfPTRRzIMQ2PGjGl3vrGxUampqZIkr9erxsZGvfzyy/7r1q5dq5ycHH3++ecBD90QRgAAQAder1cOh0PFxcVyOBztfpaYmChJSk9Pl9PpbBdYsrOzJUllZWWEEQAAELrrr79eHo9HlZWVmjJlSqfXTJ48WS0tLdq/f79Gjx4tSdq3b58kKTMzM+D3YjUNAAB9VH19vb788ktJreFjxYoVmjp1qgYMGKARI0bo+9//vnbu3Knly5fr+uuvV1VVlf7yl7/ommuu0fTp0+X1evWNb3xDiYmJWrlypbxerx566CElJydry5YtAddBGAEAoI967733NHXq1A7nZ8+erfXr16u5uVlPPvmkXn75ZR09elSpqamaNGmSli1bpmuuuUaSdOzYMf34xz/Wli1blJCQoGnTpmn58uUaMGBAwHUQRgAAgKVY2gsAACxFGAEAAJYijAAAAEsRRgAAgKUIIwAAwFKEEQAAYCnCCAAAsBRhBAAAWIowAgAALEUYAQAAliKMAAAASxFGAACApf4/La/duWir4koAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epsilon_S = 1.0\n",
        "epsilon_E = 0.01\n",
        "epsilon_decay = 30000\n",
        "\n",
        "_epsilon = lambda frame: epsilon_E + (epsilon_S - epsilon_E)*np.exp(-frame/epsilon_decay)\n",
        "plt.plot([_epsilon(frame) for frame in range(1000000)]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QrzSpXZnaBKB"
      },
      "outputs": [],
      "source": [
        "class NoopResetEnv(gym.Wrapper):\n",
        "    def __init__(self, env, noop_max=30):\n",
        "        \"\"\"Sample initial states by taking random number of no-ops on reset.\n",
        "        No-op is assumed to be action 0.\n",
        "        \"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        self.noop_max = noop_max\n",
        "        self.override_num_noops = None\n",
        "        self.noop_action = 0\n",
        "        assert env.unwrapped.get_action_meanings()[0] == 'NOOP'\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        \"\"\" Do no-op action for a number of steps in [1, noop_max].\"\"\"\n",
        "        self.env.reset(**kwargs)\n",
        "        if self.override_num_noops is not None:\n",
        "            noops = self.override_num_noops\n",
        "        else:\n",
        "            noops = self.unwrapped.np_random.integers(1, self.noop_max + 1) #pylint: disable=E1101\n",
        "        assert noops > 0\n",
        "        obs = None\n",
        "        for _ in range(noops):\n",
        "            obs, _, done, _, info = self.env.step(self.noop_action)\n",
        "            if done:\n",
        "                obs = self.env.reset(**kwargs)\n",
        "        return obs, info\n",
        "\n",
        "    def step(self, ac):\n",
        "        return self.env.step(ac)\n",
        "\n",
        "class FireResetEnv(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        \"\"\"Take action on reset for environments that are fixed until firing.\"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
        "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        self.env.reset(**kwargs)\n",
        "        obs, _, done, _, info = self.env.step(1)\n",
        "        if done:\n",
        "            self.env.reset(**kwargs)\n",
        "        obs, _, done, _, info = self.env.step(2)\n",
        "        if done:\n",
        "            self.env.reset(**kwargs)\n",
        "        return obs, info\n",
        "\n",
        "    def step(self, ac):\n",
        "        return self.env.step(ac)\n",
        "\n",
        "class EpisodicLifeEnv(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        \"\"\"Make end-of-life == end-of-episode, but only reset on true game over.\n",
        "        Done by DeepMind for the DQN and co. since it helps value estimation.\n",
        "        \"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        self.lives = 0\n",
        "        self.was_real_done  = True\n",
        "\n",
        "    def step(self, action):\n",
        "        obs, reward, done, truncated, info = self.env.step(action)\n",
        "        self.was_real_done = done\n",
        "        # check current lives, make loss of life terminal,\n",
        "        # then update lives to handle bonus lives\n",
        "        lives = self.env.unwrapped.ale.lives()\n",
        "        if lives < self.lives and lives > 0:\n",
        "            # for Qbert sometimes we stay in lives == 0 condtion for a few frames\n",
        "            # so its important to keep lives > 0, so that we only reset once\n",
        "            # the environment advertises done.\n",
        "            done = True\n",
        "        self.lives = lives\n",
        "        return obs, reward, done, truncated, info\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        \"\"\"Reset only when lives are exhausted.\n",
        "        This way all states are still reachable even though lives are episodic,\n",
        "        and the learner need not know about any of this behind-the-scenes.\n",
        "        \"\"\"\n",
        "        if self.was_real_done:\n",
        "            obs, info = self.env.reset(**kwargs)\n",
        "        else:\n",
        "            # no-op step to advance from terminal/lost life state\n",
        "            obs, _, _, _, info = self.env.step(0)\n",
        "        self.lives = self.env.unwrapped.ale.lives()\n",
        "        return obs, info\n",
        "\n",
        "class MaxAndSkipEnv(gym.Wrapper):\n",
        "    def __init__(self, env, skip=4):\n",
        "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        # most recent raw observations (for max pooling across time steps)\n",
        "        self._obs_buffer = np.zeros((2,)+env.observation_space.shape, dtype=np.uint8)\n",
        "        self._skip       = skip\n",
        "\n",
        "    def reset(self):\n",
        "        return self.env.reset()\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Repeat action, sum reward, and max over last observations.\"\"\"\n",
        "        total_reward = 0.0\n",
        "        done = None\n",
        "        for i in range(self._skip):\n",
        "            obs, reward, done, truncated, info = self.env.step(action)\n",
        "            if i == self._skip - 2: self._obs_buffer[0] = obs\n",
        "            if i == self._skip - 1: self._obs_buffer[1] = obs\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        # Note that the observation on the done=True frame\n",
        "        # doesn't matter\n",
        "        max_frame = self._obs_buffer.max(axis=0)\n",
        "\n",
        "        return max_frame, total_reward, done, truncated, info\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        return self.env.reset(**kwargs)\n",
        "\n",
        "class ClipRewardEnv(gym.RewardWrapper):\n",
        "    def __init__(self, env):\n",
        "        gym.RewardWrapper.__init__(self, env)\n",
        "\n",
        "    def reward(self, reward):\n",
        "        \"\"\"Bin reward to {+1, 0, -1} by its sign.\"\"\"\n",
        "        return np.sign(reward)\n",
        "\n",
        "class WarpFrame(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        \"\"\"Warp frames to 84x84 as done in the Nature paper and later work.\"\"\"\n",
        "        gym.ObservationWrapper.__init__(self, env)\n",
        "        self.width = 84\n",
        "        self.height = 84\n",
        "        self.observation_space = spaces.Box(low=0, high=255,\n",
        "            shape=(self.height, self.width, 1), dtype=np.uint8)\n",
        "\n",
        "    def observation(self, frame):\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "        frame = cv2.resize(frame, (self.width, self.height), interpolation=cv2.INTER_AREA)\n",
        "        return frame[:, :, None]\n",
        "\n",
        "class FrameStack(gym.Wrapper):\n",
        "    def __init__(self, env, k):\n",
        "        \"\"\"Stack k last frames.\n",
        "        Returns lazy array, which is much more memory efficient.\n",
        "        See Also\n",
        "        --------\n",
        "        baselines.common.atari_wrappers.LazyFrames\n",
        "        \"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        self.k = k\n",
        "        self.frames = deque([], maxlen=k)\n",
        "        shp = env.observation_space.shape\n",
        "        self.observation_space = spaces.Box(low=0, high=255, shape=(shp[0], shp[1], shp[2] * k), dtype=np.uint8)\n",
        "\n",
        "    def reset(self):\n",
        "        ob, info = self.env.reset()\n",
        "        for _ in range(self.k):\n",
        "            self.frames.append(ob)\n",
        "        return self._get_ob(), info\n",
        "\n",
        "    def step(self, action):\n",
        "        ob, reward, done, info = self.env.step(action)\n",
        "        self.frames.append(ob)\n",
        "        return self._get_ob(), reward, done, info\n",
        "\n",
        "    def _get_ob(self):\n",
        "        assert len(self.frames) == self.k\n",
        "        return LazyFrames(list(self.frames))\n",
        "\n",
        "class ScaledFloatFrame(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        gym.ObservationWrapper.__init__(self, env)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        # careful! This undoes the memory optimization, use\n",
        "        # with smaller replay buffers only.\n",
        "        return np.array(observation).astype(np.float32) / 255.0\n",
        "\n",
        "class LazyFrames(object):\n",
        "    def __init__(self, frames):\n",
        "        \"\"\"This object ensures that common frames between the observations are only stored once.\n",
        "        It exists purely to optimize memory usage which can be huge for DQN's 1M frames replay\n",
        "        buffers.\n",
        "        This object should only be converted to numpy array before being passed to the model.\n",
        "        You'd not believe how complex the previous solution was.\"\"\"\n",
        "        self._frames = frames\n",
        "        self._out = None\n",
        "\n",
        "    def _force(self):\n",
        "        if self._out is None:\n",
        "            self._out = np.concatenate(self._frames, axis=2)\n",
        "            self._frames = None\n",
        "        return self._out\n",
        "\n",
        "    def __array__(self, dtype=None):\n",
        "        out = self._force()\n",
        "        if dtype is not None:\n",
        "            out = out.astype(dtype)\n",
        "        return out\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._force())\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self._force()[i]\n",
        "\n",
        "def make_atari(env_id, render_mode=None):\n",
        "    env = gym.make(env_id, render_mode = render_mode)\n",
        "    assert 'NoFrameskip' in env.spec.id\n",
        "    env = NoopResetEnv(env, noop_max=30)\n",
        "    env = MaxAndSkipEnv(env, skip=4)\n",
        "    return env\n",
        "\n",
        "def wrap_deepmind(env, episode_life=True, clip_rewards=True, frame_stack=False, scale=False):\n",
        "    \"\"\"Configure environment for DeepMind-style Atari.\n",
        "    \"\"\"\n",
        "    if episode_life:\n",
        "        env = EpisodicLifeEnv(env)\n",
        "    if 'FIRE' in env.unwrapped.get_action_meanings():\n",
        "        env = FireResetEnv(env)\n",
        "    env = WarpFrame(env)\n",
        "    if scale:\n",
        "        env = ScaledFloatFrame(env)\n",
        "    if clip_rewards:\n",
        "        env = ClipRewardEnv(env)\n",
        "    if frame_stack:\n",
        "        env = FrameStack(env, 4)\n",
        "    return env\n",
        "\n",
        "\n",
        "\n",
        "class ImageToPyTorch(gym.ObservationWrapper):\n",
        "    \"\"\"\n",
        "    Image shape to num_channels x weight x height\n",
        "    \"\"\"\n",
        "    def __init__(self, env):\n",
        "        super(ImageToPyTorch, self).__init__(env)\n",
        "        old_shape = self.observation_space.shape\n",
        "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], old_shape[0], old_shape[1]), dtype=np.uint8)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.swapaxes(observation, 2, 0)\n",
        "\n",
        "\n",
        "def wrap_pytorch(env):\n",
        "    return ImageToPyTorch(env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DAIUpXjBpTl2"
      },
      "outputs": [],
      "source": [
        "def compute_td_loss(batch_size, device):\n",
        "    state, action, reward, next_state, done = replay_buffer.replay(batch_size)\n",
        "    state      = torch.tensor(state).to(device)\n",
        "    next_state = torch.tensor(np.array(next_state), requires_grad=False).to(device)\n",
        "    action     = torch.LongTensor(action).to(device)\n",
        "    reward     = torch.FloatTensor(reward).to(device)\n",
        "    done       = torch.FloatTensor(done).to(device)\n",
        "\n",
        "    q_values      = model(state)\n",
        "    next_q_values = model(next_state)\n",
        "\n",
        "    q_value          = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
        "    next_q_value     = next_q_values.max(1)[0]\n",
        "    expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
        "\n",
        "    loss = (q_value - expected_q_value.data).pow(2).mean()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BMTQQk4RbE0Q"
      },
      "outputs": [],
      "source": [
        "class CnnDQN(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions):\n",
        "        super(CnnDQN, self).__init__()\n",
        "\n",
        "        self.input_shape = input_shape\n",
        "        self.num_actions = num_actions\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.feature_size(), 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, self.num_actions)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.float()\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def feature_size(self):\n",
        "        return self.features(torch.autograd.Variable(torch.zeros(1, *self.input_shape))).view(1, -1).size(1)\n",
        "\n",
        "    def act(self, state, epsilon):\n",
        "        with torch.no_grad():\n",
        "            if random.random() > epsilon:\n",
        "                state   = torch.FloatTensor(state).unsqueeze(0)\n",
        "                state = state.to(device)\n",
        "                q_value = self.forward(state)\n",
        "                action  = q_value.max(1)[1].item()\n",
        "            else:\n",
        "                action = random.randrange(env.action_space.n)\n",
        "        return action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "DwptusQyZYkP",
        "outputId": "ad08ba12-d6fb-48ab-eb0c-5bc3992bb11d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIkAAACwCAYAAAA7UU2sAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAD/ElEQVR4nO3dv28bdRyH8bd/NE0bKyF1FCIhQQe6AFEnhIrEgoSEmNhY6B+AGBALMwP/AyxMsLGwMdAFdUEiSysYQAoirUQFyE0b6gbHiY+haqf0nkLOPjt5XlNyPp0/UR7563MuukZRFEWkEs26B9D0MxIhIxEyEiEjETISoXbZg+efOvzhyxcXsnK2NZaBHlrsdB59/Xe/n1k8Ux+emctg6WySpD0YZn67X7p/kaS/tpSkkSRZ+PNuGqPJ/dwffHP70O2lkXx4aXEsw5BGo5GXX3oxzWYzRVHkux82Mtzfr2WWo7jz/Fq23lhPkiz9+kcufL1Run/Raubnd15N0WomRZGLn13Jqd29SYxayuVGyEiEjETISISMRMhIhIxEyEiEjETISISMRMhIhIxEyEiESi8VqEtRFPn+2vWHl1XM5GUCSbL8y610fn9wjUZz7wD3bxyM8sKXVx993/5nOLbZ/oupjCRJ+ru7dY9wZO3BMO3Bk/+iG0nO9O6Nb6D/qTSS9bffn9QcmmKNsv/g6/V6k5xFNet2u4du942rkJEIGYmQkQgZiZCRCJWeAn/x3muTnEU1u/zp1UO3l36Ydvu3n8YyjGaLy42QkQgZiZCRCBmJkJEIGYmQkQgZiZCRCBmJkJEIGYmQkQgZiZCRCBmJkJEIGYmQkQgZiZCRCBmJkJEIGYmQkQgZiZCRCBmJkJEIGYmQkQgZiZCRCFV6A4LVc+ey2FlIkvTu3M32zk6Vh1dNKo1kZXk5zzy9miQ5GBVjiaTRbCVJihHfGkTVmLnl5s2Pv8rrH31e9xgnysxF0po7nVZ7ru4xTpSZi0STN7V3znqcbz95N0UxqnuME2XmIhnc2657hBPH5UbISISMRMhIhIxEqNKzm8FwL/37D276PNyfjrtj6+gqjWTzxs1s3rhZ5SE1BVxuhIxEyEiEjETISISMRMhIhIxEyEiEjETISISMRMhIhIxEyEiEjETISISMRMhIhIxEyEiEjETISISMRMhIhIxEyEiEjETISISMRMhIhIxEyEiEjETISISMRMhIhIxEyEiEjETISISMRMhIhIxEyEiEjETISISMRMhIhIxEyEiEjETISISMRMhIhIxEyEiEjETISITadQ+g6ux15rPXmU+SnLo/yOmd3UqOayTHyF/rz+bWpQtJkpXrWzl/5cdKjutyI2QkQkYiZCRCRiJkJEJGImQkQkYiZCRCfix/3BRF5Yc0kmNkbWMzq9e2kiTN/YPKjlsayXOvvFXZE2l2NYri8a9PvV5vkrOoZt1u99DtvnEVMhIhIxEyEiEjETISISMRMhIhIxEyEiEjESr9242U+EqiJ2AkQkYiZCRCRiJkJEL/AuQ8p2/W0w3BAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 160x210 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "env_id = \"PongNoFrameskip-v4\"\n",
        "env    = make_atari(env_id, render_mode='rgb_array')\n",
        "env    = wrap_deepmind(env)\n",
        "env    = wrap_pytorch(env)\n",
        "\n",
        "# model = CnnDQN(env.observation_space.shape, env.action_space.n)\n",
        "\n",
        "# model = model.cuda()\n",
        "\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
        "\n",
        "# replay_initial = 10000\n",
        "# replay_buffer = Replay_Buffer(100000)\n",
        "\n",
        "model = torch.load('pingpong_dqn.pth', map_location=torch.device('cpu'))\n",
        "model = model.to(device)\n",
        "\n",
        "def save_frames_as_gif(frames, path='./', filename='pong.gif'):\n",
        "\n",
        "    #Mess with this to change frame size\n",
        "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi=72)\n",
        "\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis('off')\n",
        "\n",
        "    def animate(i):\n",
        "        patch.set_data(frames[i])\n",
        "\n",
        "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=10)\n",
        "\n",
        "    anim.save(path + filename, writer='imagemagick', fps=6)\n",
        "\n",
        "epsilon = _epsilon(1400000)\n",
        "state, _ = env.reset()\n",
        "\n",
        "frames = []\n",
        "for t in tqdm(range(1000)):\n",
        "    #Render to frames buffer\n",
        "    frames.append(env.render())\n",
        "    action = model.act(state, epsilon)\n",
        "    state, _, done, _, _ = env.step(action)\n",
        "    if done:\n",
        "        break\n",
        "\n",
        "save_frames_as_gif(frames)\n",
        "clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmJ9DfmboJqK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
